{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 收集数据\n",
    "- tweet无法访问 :)\n",
    "- 从github仓库[https://github.com/udacity/new-dand-advanced-china](https://github.com/udacity/new-dand-advanced-china)中下载文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding=utf-8 -*-\n",
    "import requests\n",
    "\n",
    "def download(url):\n",
    "    with open(url.split('/')[-1], mode=\"wb\") as f:\n",
    "        respone = requests.get(url)\n",
    "        f.write(respone.content)\n",
    "        \n",
    "# 下载 image-predictions.tsv\n",
    "image_prediction_url = \"https://raw.githubusercontent.com/udacity/new-dand-advanced-china/master/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/WeRateDogs%E9%A1%B9%E7%9B%AE/image-predictions.tsv\"\n",
    "download(image_prediction_url)\n",
    "# 下载 twitter_archive_enhanced.csv\n",
    "twitter_archive_enhanced_url = \"https://raw.githubusercontent.com/udacity/new-dand-advanced-china/master/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/WeRateDogs%E9%A1%B9%E7%9B%AE/twitter-archive-enhanced.csv\"\n",
    "download(twitter_archive_enhanced_url)\n",
    "# 下载 tweet_json.txt\n",
    "tweet_json_url = \"https://raw.githubusercontent.com/udacity/new-dand-advanced-china/master/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/WeRateDogs%E9%A1%B9%E7%9B%AE/tweet_json.txt\"\n",
    "download(tweet_json_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 评估数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用pandas读取数据文件\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions = pd.read_csv(\"image-predictions.tsv\", sep='\\t')\n",
    "image_predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_predictions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 处理和评估tweet_json.txt数据\n",
    "import json\n",
    "with open(\"tweet_json.txt\", 'r') as json_file:\n",
    "    for data in json_file.readlines():\n",
    "        print(json.dumps(json.loads(data), indent=4, sort_keys=False, ensure_ascii=True))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逐行读取tweet_json.txt文件并添加到pandas DataFrame中，（至少）包含 tweet ID、retweet_count和favorite_count字段...\n",
    "# 提出问题，放到list中，然后通过 'id_str': list1, 'fav_count': list2的方式创建df的效率是否更高？\n",
    "df_tweet = pd.DataFrame()\n",
    "\n",
    "# 观察tweet_json.txt后，对以下数据感兴趣：\n",
    "# retweet_count favorite_count full_text retweeted source favorited\n",
    "with open(\"tweet_json.txt\", 'r') as json_file:\n",
    "    index = ['id', 'retweet_count', 'favorite_count', 'full_text', 'retweeted', 'source', 'favorited']\n",
    "    for data in json_file.readlines():\n",
    "        dict_data = json.loads(data)\n",
    "        \n",
    "        data = []\n",
    "        for idx in index:\n",
    "            data.append(dict_data[idx])\n",
    "        \n",
    "        s_tweet = pd.Series(data, index=index)\n",
    "        retweet_count = dict_data[u'retweet_count']\n",
    "        df_tweet = df_tweet.append(s_tweet, ignore_index=True)\n",
    "\n",
    "df_tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "witter_archive_enhanced = pd.read_csv(\"twitter-archive-enhanced.csv\")\n",
    "witter_archive_enhanced.info()\n",
    "witter_archive_enhanced.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "witter_archive_enhanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 质量\n",
    "##### `df_tweet` 表格\n",
    "- favorite_count、id、retweet_count应该是int64类型，而不是浮点浮点类型\n",
    "- favorited 和 retweeted 的值都是零，需要删除这两列\n",
    "\n",
    "##### `twitter_archive_enhanced` 表格\n",
    "- doggo floofer pupper puppo字段有\"None\"这是python关键字，在csv体现为字符串，这应该在表示空\n",
    "- in_reply_to_status_id和in_reply_to_user_id，只有78个值，这两个列的数据很可能没用\n",
    "- timestamp、retweeted_status_timestamp现在是object类型，要转换为时间类型\n",
    "- rating_denominator不是10的需要清理掉, 比如170是最大值是不对的\n",
    "- rating_numerator分子小于rating_denominator的需要清理掉\n",
    "- expanded_urls的单条记录中有重复的url地址，清理清理只保留一个\n",
    "- name字段有字符串\"None\"，有的跟text中的描述不符，比如\"a\"\n",
    "\n",
    "#### 清洁度\n",
    "##### `df_tweet` 表格\n",
    "- source字段内容是html文本，需要更加简洁，只需要获取该html的text部分即可\n",
    "- 通过witter_archive_enhanced.tweet_id和df_tweet.id和image_predictions.tweet_id关联创建新的表格twitter_archive_master.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 清理前的备份\n",
    "df_tweet_clean = df_tweet.copy()\n",
    "witter_archive_enhanced_clean = witter_archive_enhanced.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# favorite_count id retweet_count应该是int64类型，现在做格式转换 long\n",
    "for i in ['favorite_count', 'id', 'retweet_count']:\n",
    "    df_tweet_clean[i] = df_tweet_clean[i].astype(long)\n",
    "df_tweet_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 顺便调整列的顺序, 排除favorited和retweeted列\n",
    "index = ['id', 'retweet_count', 'favorite_count', 'full_text', 'source']\n",
    "df_tweet_clean = df_tweet_clean.reindex_axis(index, axis=1)\n",
    "df_tweet_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_denominator不是10的需要清理掉\n",
    "witter_archive_enhanced_clean = witter_archive_enhanced[witter_archive_enhanced[\"rating_denominator\"]==10]\n",
    "witter_archive_enhanced_clean.info()\n",
    "witter_archive_enhanced_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_numerator分子小于rating_denominator的需要清理掉\n",
    "witter_archive_enhanced_clean = witter_archive_enhanced_clean[witter_archive_enhanced_clean[\"rating_numerator\"] > witter_archive_enhanced_clean[\"rating_denominator\"]]\n",
    "witter_archive_enhanced_clean.info()\n",
    "witter_archive_enhanced_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "witter_archive_enhanced_clean.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp、retweeted_status_timestamp现在是object类型，要转换为时间类型\n",
    "witter_archive_enhanced_clean['timestamp'] = pd.to_datetime(witter_archive_enhanced_clean['timestamp'],format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "witter_archive_enhanced_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# expanded_urls的单条记录中有重复的url地址，清理清理只保留一个\n",
    "witter_archive_enhanced_clean['expanded_urls_one'], witter_archive_enhanced_clean['expanded_urls_others'] = witter_archive_enhanced_clean['expanded_urls'].str.split(',', 1).str\n",
    "witter_archive_enhanced_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source字段内容是html文本，需要更加简洁，只需要获取该html的text部分即可\n",
    "witter_archive_enhanced_clean['source1'], witter_archive_enhanced_clean['source2']= witter_archive_enhanced_clean.source.str.split('>', 1).str\n",
    "witter_archive_enhanced_clean['source_text'], witter_archive_enhanced_clean['source4']= witter_archive_enhanced_clean.source2.str.split('<', 1).str\n",
    "witter_archive_enhanced_clean = witter_archive_enhanced_clean.drop('source1', axis=1)\n",
    "witter_archive_enhanced_clean = witter_archive_enhanced_clean.drop('source2', axis=1)\n",
    "witter_archive_enhanced_clean = witter_archive_enhanced_clean.drop('source4', axis=1)\n",
    "witter_archive_enhanced_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看source的分布\n",
    "witter_archive_enhanced_clean.source_text.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改df_tweet_clean的 id 为 tweet_id\n",
    "df_tweet_clean['tweet_id'] = df_tweet_clean['id']\n",
    "# 只保留部分列\n",
    "index = ['tweet_id', 'retweet_count', 'favorite_count']\n",
    "df_tweet_clean = df_tweet_clean.reindex_axis(index, axis=1)\n",
    "index = ['tweet_id', 'name','rating_numerator','rating_denominator','timestamp', 'text', 'source_text', 'expanded_urls_one','doggo','floofer','pupper','puppo']\n",
    "witter_archive_enhanced_clean = witter_archive_enhanced_clean.reindex_axis(index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过 witter_archive_enhanced.tweet_id 和 df_tweet.id关联创建新的表格twitter_archive_master.csv\n",
    "twitter_archive_master = pd.merge(witter_archive_enhanced_clean, df_tweet_clean,\n",
    "                            on=['tweet_id'], how='left')\n",
    "twitter_archive_master.info()\n",
    "twitter_archive_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把数据保存到 twitter_archive_master.csv\n",
    "twitter_archive_master.to_csv('twitter_archive_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
